{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "You will need to complete this notebook.  The final result should follow the style of our Recipe for ML (see Geron, Appendix B) as appropriate\n",
    "\n",
    "Your task is to complete the coding sections, and to add sections that discus the problem, the data, and your exploration process.  We have only supplied the required coding sections.  The rest is up to you.\n",
    "\n",
    "1. Code sections\n",
    "    - We have given you an outline of the code, with missing elements\n",
    "    - The <span style=\"color:red\">Red Section Headers</span> contain code templates that you need to complete\n",
    "        - We have supplied the signature for the functions, and a specification\n",
    "        - Your job is to implement the function so as to satisfy the specification\n",
    "        - Please **DO NOT** change function signatures in the templates, or variable names on the left hand side of existing code without approval from the instructor or GA\n",
    "        - We will test your code for correctness by calling the functions in the template, and evaluating certain variables (whose values you will compute).  If you change these, it will make evaluation more difficult.\n",
    "        \n",
    "1. Other sections\n",
    "    - Add all the sections in our \"reciple for ML\" (e.g. see Geron Appendix B) as appropriate\n",
    "    - Consider this an example of what you would submit as part of a take-home job interview\n",
    "    - We want to see *how* you approached the problem, not just the solution\n",
    "\n",
    "     \n",
    "**REMEMBER** Working code and correct answers give partial credit.  To get full credit, your notebook should reflect your process of thinking and exploration (i.e., lots of markdown, graphs where appropriate, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"./assignment_1_answers.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Import any other modules you need</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your imports\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn.preprocessing as pre_proc\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "The purpose of this assignment is to serve as a \"check-point\" on your knowledge of\n",
    "- Jupyter\n",
    "- NumPy, Pandas\n",
    "- The very basic elements of sklearn\n",
    "- Notebook style\n",
    "\n",
    "You will construct a linear regression model to predict the return of a ticker, given the returns of an index (SPY).  You will source the data, assemble it into a useful form, and transform it as needed.  Finally, you will use sklearn to build the model and evaluate it using the RMSE Performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Create function to obtain the train and test data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-58124bb156fa>, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-58124bb156fa>\"\u001b[1;36m, line \u001b[1;32m33\u001b[0m\n\u001b[1;33m    Create the function body according to the spec\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def getData(ticker, indx):\n",
    "    \"\"\"\n",
    "    Retrieve two timeseries: one for a ticker and one for an index.\n",
    "    Return a DataFrame containing the two timeseries.\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    ticker, indx: Strings representing the stock symbol for \"ticker\" and the \"index\"\n",
    "    \n",
    "    The two timeseries are in separate CSV files.  The code below will construct the names of the files from\n",
    "    the stock symbol strings.\n",
    "    \n",
    "    The files contain multiple features. The feature of interest to us is \"Close\", which is the closing price.\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    df: a DataFrame with the following properties\n",
    "    \n",
    "    df.index should be the dates in the timeseries\n",
    "    df should have (at least) 2 columns, with names:\n",
    "    \"Dependent\"\n",
    "    \"Independent\"\n",
    "    \n",
    "    df.loc[:, \"Dependent\"] should be the timeseries of the \"Close\" attribute for the ticker\n",
    "    df.loc[:, \"Independent\"] should be the timeseries for the \"Close\" attribute of the index against which we are computing beta.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the name of the files containing the ticker and the \"index\"\n",
    "    ticker_file = \"F:/nyu 19spring/7773/assign1/data/assignment_1/{t}.csv\".format(t=ticker)\n",
    "    indx_file   = \"F:/nyu 19spring/7773/assign1/data/assignment_1/{t}.csv\".format(t=indx)\n",
    "    \n",
    "    Create the function body according to the spec\n",
    "    df1=pd.read_csv(ticker_file,index_col='Date')\n",
    "    df2=pd.read_csv(indx_file,index_col='Date')\n",
    "    df=pd.merge(df1.loc[:,['Close']],df2.loc[:,['Close']],on='Date')\n",
    "    df.columns = ['Dependent','Independent']\n",
    "    \n",
    "    # Change the return statement as appropriate\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticker: BA (Boeing), Index: SPY (the ETF for the S&P 500)\n",
    "df = getData(\"BA\", \"SPY\")\n",
    "X = df.loc[:, [\"Independent\"] ]\n",
    "y = df.loc[:, [\"Dependent\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Create function to split the full data into train and test data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, seed=42):\n",
    "    \"\"\"\n",
    "    Split the data into a training and test set\n",
    "    \n",
    "    The training data should span the date range from 1/1/2018 to 6/30/2018\n",
    "    The test data should span the date range from 7/1/2018 to 7/31/2018\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: DataFrame containing the independent variable(s) (i.e, features, predictors)\n",
    "    y: DataFrame containing the dependent variable (i.e., the target)\n",
    "    \n",
    "    Optional\n",
    "    --------\n",
    "    seed: Integer used as the seed for a random number generator\n",
    "      You don't necessarily NEED to use a random number generator but, if you do, please use the default value for seed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_train: DataFrame containing training data for independent variable(s)\n",
    "    X_test:  DataFrame containing test data for independent variable(s)\n",
    "    y_train: DataFrame containing training data for dependent variable\n",
    "    y_test:  DateFrame containing test data for dependent variable\n",
    "    \"\"\"\n",
    "    # IF  you need to use a random number generator, use rng.\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # Create the function body according to the spec\n",
    "    X_train=X.loc['2018-01-02':'2018-06-29',:]\n",
    "    y_train=y.loc['2018-01-02':'2018-06-29',:]\n",
    "    X_test=X.loc['2018-07-02':'2018-07-31',:]\n",
    "    y_test=y.loc['2018-07-02':'2018-07-31',:]\n",
    "    \n",
    "    # Change the return statement as appropriate\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and a test set\n",
    "X_train, X_test, y_train, y_test = split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Create a function to perform any other preparation of the data needed</span>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData( dfList ):\n",
    "    \"\"\"\n",
    "    Prepare each DataFrame df in the list of DataFrames for use by the model\n",
    "    \n",
    "    This is the time to convert each of your datasets into the form consumed by your model.  For example:\n",
    "    - do any columns of df needed to be converted into another form ?\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dfList:  A list of DataFrames\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    finalList: A list of DataFrames.  There is a one to one correspondence between items in\n",
    "      dfList and finalList, so\n",
    "        \n",
    "      len(finalList) == len(dfList)\n",
    "    \n",
    "    Consider the DataFrame at position i of dfList (i.e, dfList[i]).\n",
    "    The corresponding element of finalList (i.e, finalList[i]) will have changed dfList[i] into the DataFrame\n",
    "    that will be used as input by the sklearn model.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the function body according to the spec\n",
    "    finalList=[]\n",
    "    for i in range(0,len(dfList)):\n",
    "        df=dfList[i]\n",
    "        daily_return = df.pct_change(1)\n",
    "        daily_return.dropna(axis=0, how='any',inplace=True)\n",
    "        finalList.append(daily_return)\n",
    "    return finalList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Transform the raw data, if needed</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed: turn each of the \"raw\" X_train, X_test, y_train, y_test into a \"transfomred\" versions containing the features needed by the model\n",
    "# - you will need to replace the empty list argument\n",
    "X_train, X_test, y_train, y_test = prepareData( [ X_train, X_test, y_train, y_test ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Create function to convert the DataFrames to ndarrays</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd2ndarray( dfList ):\n",
    "    \"\"\"\n",
    "    For each DataFrame in the list dfList, prepare the ndarray needed by the sklearn model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dfList: List of DataFrames\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    ndList: a list of ndarrays\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the function body according to the spec\n",
    "    ndlist=[]\n",
    "    for i in range(0,len(dfList)):\n",
    "        ndlist.append((np.array(dfList[i].iloc[:,0])).reshape(-1,1))\n",
    "    # Change the return statement as appropriate\n",
    "    return ndlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn takes ndarrays as arguments, not DataFrames; convert your DataFrames to the appropriate ndarray\n",
    "# You will need to replace the empty list argument\n",
    "X_train, X_test, y_train, y_test = pd2ndarray( [X_train, X_test, y_train, y_test] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Disover and Visualize Data to gain insights\n",
    "I do this on the trainning data only! No peeking at the test data!  \n",
    "    We can get some hints from the figure of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the target vs one feature\n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(1,1,1)\n",
    "xlabel='SPY'\n",
    "ylabel='Ticker'\n",
    "_ = ax.scatter(X_train, y_train,  color='black')\n",
    "_ = ax.set_xlabel(xlabel)\n",
    "_ = ax.set_ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship between SPY and Ticker could be linear. \n",
    "\n",
    "That will be our initial hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Create function to return the sklearn model you need</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    \"\"\"\n",
    "    Create an sklearn model object\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model: An sklearn model object,\n",
    "    i.e., responds to model.fit(), model.predict()\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the function body according to the spec\n",
    "    regr = linear_model.LinearRegression()\n",
    "    \n",
    "    # Change the return statement as appropriate\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Create function to compute a Root Mean Squared Error</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRMSE( target, predicted ):\n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Error (RMSE)\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    target: ndarray of target values\n",
    "    predicted: ndarray of predicted values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rmse: a Scalar value containg the RMSE\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the function body according to the spec\n",
    "    rmse = np.sqrt( mean_squared_error(target,  predicted))\n",
    "        \n",
    "    # Change the return statement as appropriate\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "model = createModel()\n",
    "\n",
    "# Train the model using the training sets\n",
    "_ = model.fit(X_train, y_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', model.intercept_, model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Evaluate in and out of sample Root Mean Squared Error</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions:\n",
    "# predict out of sample: You will need to change the None argument\n",
    "y_pred_test = model.predict( X_test )\n",
    "\n",
    "# predict in sample: You will need to change the None argument\n",
    "y_pred_train = model.predict( X_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the in-sample fit\n",
    "# - you will need to replace the None's below with the appropriate argument\n",
    "rmse_insample = computeRMSE( y_train, y_pred_train )\n",
    "print(\"RMSE (train): {r:2.3f}\".format(r=rmse_insample))\n",
    "\n",
    "# Compute the out of sample fit\n",
    "# - you will need to replace the None's below with the appropriate argument\n",
    "rmse_outOfsample = computeRMSE( y_test, y_pred_test)\n",
    "print(\"RMSE (test): {r:2.3f}\".format(r=rmse_outOfsample))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These numbers mean that**  \n",
    "**Relative to the given training set**  \n",
    "**our ticker predictions of training set are with +/- RMSE(train)**  \n",
    "**our ticker predictions of test set are with +/- RMSE(test)**  \n",
    "**Let's visualize the fit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Visualize the fit and the distribution of errors</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted ylabel (red) and true  (black)\n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(1,1,1)\n",
    "\n",
    "_ = ax.scatter(X_test, y_test, color='black', label=\"test\")\n",
    "_ = ax.scatter(X_test, y_pred_test, color=\"red\",   label=\"predicted\")\n",
    "\n",
    "_ = ax.plot(X_test, y_pred_test, color=\"blue\")\n",
    "_ = ax.set_xlabel(xlabel)\n",
    "_ = ax.set_ylabel(ylabel)\n",
    "_ = ax.legend()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "_ = ax.hist( (y_test - y_pred_test) )\n",
    "_ = ax.set_xlabel(\"Error\")\n",
    "_ = ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Through this figure, we can see the errors are distributed among the different intervals. Both tails and middle have the problem of fitting.**  \n",
    "**Then we take a look at in-sample fitting situations and errors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Aside: training data fitting situations and errors. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(1,1,1)\n",
    "\n",
    "_ = ax.scatter(X_train, y_train, color=\"black\",    label=\"train\")\n",
    "_ = ax.scatter(X_train, y_pred_train, color=\"red\", label=\"model\")\n",
    "\n",
    "_ = ax.plot(X_train, y_pred_train, color=\"blue\")\n",
    "_ = ax.set_xlabel(xlabel)\n",
    "_ = ax.set_ylabel(ylabel)\n",
    "_ = ax.legend()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "_ = ax.hist( (y_train - y_pred_train) )\n",
    "_ = ax.set_xlabel(\"Error\")\n",
    "_ = ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Please answer the following questions</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are your thoughts/theories on the in sample vs out of sample performance ?\n",
    "- Repeat the experiment using ticker FB (Facebook) rather than ticker BA (Boeing)\n",
    "    - What are your thoughts of in sample vs out of sample performance, especially compared to BA\n",
    "        - Maybe our predictor (SPX Index return) was *not* a great predictor for FB\n",
    "        - any thoughts for a better one ?\n",
    "            - run the experiment using another predictor; there are more timeseries in the same directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Answer**  \n",
    " - The training and test data have very close RMSE, which are 0.014 and 0.011. Therefore, overfiting does not exist.  \n",
    "   After reviewing the figures, errors are distributed in a most range of training data although two short tails have a good fit. Therefore, both training data and test data have fitting problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - I visualize the fit and distribution of erros by using ticker FB (Facebook) rather than ticker BA (Boeing). The first two is from test data. The last two is from trainning data. The RMSE of training data is 0.016, the RMSE of test data is 0.043.  \n",
    "   Through the pictures below and RMSE, we can see that SPX Index return is not a great predictor for FB. And there may exist overfitting problems, since RMSE of test data is much bigger than RMSE of training data.\n",
    " \n",
    "![alt text](https://raw.githubusercontent.com/EmmaZhangXuan/IMG/master/1.png\")\n",
    "![alt text](https://raw.githubusercontent.com/EmmaZhangXuan/IMG/master/untitled1.png\")\n",
    "![alt text](https://raw.githubusercontent.com/EmmaZhangXuan/IMG/master/untitled2.png\")\n",
    "![alt text](https://raw.githubusercontent.com/EmmaZhangXuan/IMG/master/untitled3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - I used QQQ and XLK as predictors because they are index. Here are outcomes of RMSE.  \n",
    " \n",
    "| Predictor     | Ticker        | RMSE (train)   | RMSE (test)    |\n",
    "| ------------- |:-------------:|:--------------:|---------------:|\n",
    "| XLK           | BA            | 0.016          |0.013           |\n",
    "| QQQ           | BA            | 0.016          |0.012           |\n",
    "| XLK           | FB            | 0.015          |0.039           |\n",
    "| QQQ           | FB            | 0.015          |0.039           | \n",
    "   \n",
    " - We can see that the RMSE(test) of QQQ and XLK are very close. Therefore, QQQ and XLK play the similar effects on predicting the ticker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Extra credit</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assume our test set remains unchanged\n",
    "    - Does changing the date range of our training data affect the Performance metric (test RMSE)\n",
    "        - holding constant the last date of the training data\n",
    "        - plot the Performance metric versus the number of days of training data\n",
    "        \n",
    "- What are some of the challenges of timeseries data ?\n",
    "    - The Performance metric is an average that doesn't take an time-varying pattern of error into account\n",
    "        - show a scatter plot of error versus distance from date of last training point\n",
    "            - any pattern ? Theories ?\n",
    "    - We split train/test so that each has a continous date range\n",
    "        - we didn't use the standard sklearn `sklearn.model_selection.train_test_split`, which shuffles data\n",
    "            - what are the consideratons of shuffling data when we are dealing with timeseries ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**  \n",
    " -  According to the figure below, changing the date range of our training data does not affect the Performance metric (test RMSE).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsenew = np.zeros(shape=(len(X_train)-1,1))\n",
    "nddays = np.zeros(shape=(len(X_train)-1,1))\n",
    "\n",
    "for i in range(0,len(X_train)-1):\n",
    "    X_newtrain=X_train[i:]\n",
    "    y_newtrain=y_train[i:]\n",
    "    _ = model.fit(X_newtrain, y_newtrain)\n",
    "    y_pred_test = model.predict( X_test )\n",
    "    rmse = computeRMSE( y_test, y_pred_test )\n",
    "    rmsenew[i,0]=rmse\n",
    "    nddays[i,0]=len(X_train)-i\n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(1,1,1)\n",
    "_ = ax.scatter(nddays, rmsenew, color=\"red\")\n",
    "_ = ax.set_xlabel('the number of days of training data')\n",
    "_ = ax.set_ylabel('test RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Below is a scatter plot of error versus distance from date of last training point. We can see that points are overall evenly distributed on both sides of 0. Therefore, distance from date of last training point does not play a significant effect on errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.fit(X_train, y_train)\n",
    "y_pred_test = model.predict( X_test )\n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(1,1,1)\n",
    "_ = ax.scatter(np.arange(1,len(X_test)+1), y_test - y_pred_test, color=\"red\")\n",
    "_ = ax.plot(np.arange(1,len(X_test)+1), y_test - y_pred_test, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - When we shuffling time series data, we may ignore the temporal components inherent in the problem.Shuffling data assumes that there is no relationship between the observations, that each observation is independent. However, this is close relationship between time series data, such as stock prices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
